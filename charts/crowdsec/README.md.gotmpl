{{ template "chart.header" . }}
{{ template "chart.deprecationWarning" . }}

{{ template "chart.badgesSection" . }}

{{ template "chart.description" . }}

- [Chart Repository](#chart-repository)
- [Installing the Chart](#installing-the-chart)
- [Uninstalling the Chart](#uninstalling-the-chart)
- [Authentication](#authentication)
  - [Auto registration token](#auto-registration-token)
  - [TLS client authentication](#tls-client-authentication)
  - [Cleaning of stale agents / appsec registration in the LAPI](#cleaning-of-stale-agents--appsec-registration-in-the-lapi)
- [HA configuration for the LAPI pods](#ha-configuration-for-the-lapi-pods)
  - [Database setup](#database-setup)
  - [CrowdSec setup](#crowdsec-setup)
  - [HA Test](#ha-test)
- [Setup for AppSec (WAF)](#setup-for-appsec-waf)
  - [With Traefik](#with-traefik)
  - [With Nginx](#with-nginx)
- [Values](#values)

## Chart Repository

```sh
helm repo add crowdsec https://crowdsecurity.github.io/helm-charts
helm repo update
```

## Installing the Chart

Before installing the chart, you need to understand some [concepts](https://docs.crowdsec.net/docs/concepts) of Crowdsec.
So you can configure well the chart and being able to parse logs and detect attacks inside your Kubernetes cluster.

Here is a [blog post](https://crowdsec.net/blog/kubernetes-crowdsec-integration/) about crowdsec in kubernetes.

```sh
# Create namespace for crowdsec
kubectl create ns crowdsec
# Install helm chart with proper values.yaml config
helm install crowdsec crowdsec/crowdsec -f crowdsec-values.yaml -n crowdsec
```

## Uninstalling the Chart

```sh
helm delete crowdsec -n crowdsec
```

## Authentication

This charts support two types of authentication between the agents / appsec pods and the LAPI: an auto registration token and TLS client authentication.

### Auto registration token

By default, this chart makes use of an auto registration token completely handled by the chart.
This is setup with the following part in the `values.yaml` file. Make sure to adapt to the pod IP ranges used by your cluster. 

Also, when you modify the `config.config.yaml.local` entry in your own `values.yaml` make sure to put this piece in it as well.

```yaml
config:
  config.yaml.local: |
    api:
      server:
        auto_registration: # Activate if not using TLS for authentication
          enabled: true
          token: "${REGISTRATION_TOKEN}" # /!\ Do not modify this variable (auto-generated and handled by the chart)
          allowed_ranges: # /!\ Make sure to adapt to the pod IP ranges used by your cluster
            - "127.0.0.1/32"
            - "192.168.0.0/16"
            - "10.0.0.0/8"
            - "172.16.0.0/12"
```

### TLS client authentication

Currently TLS authentication is only possible between the agent and the LAPI as appsec doesn't support HTTPS yet.
The below configuration will activate TLS on the LAPI and TLS client authentication for the agent. 
Certificates are renewed by default with [cert-manager](https://github.com/cert-manager/cert-manager).

```yaml
tls:
  enabled: true
  agent:
    tlsClientAuth: true
```

### Cleaning of stale agents / appsec registration in the LAPI

Both methods add a machine per pod in the LAPI. These aren't automatically cleaned and the list of machines can become large over time.
Crowdsec offers a [flush option](https://docs.crowdsec.net/docs/next/configuration/crowdsec_configuration/#flush) to clean them up. 
Add the `flush:` part to your `db_config`.

```yaml
config:
  config.yaml.local: |
    db_config:
      flush:
        agents_autodelete:
          cert: 60m # This is TLS client authentication
          login_password: 60m # This includes the auto registration token as well
        ## Flush both login types if the machine has not logged in for 60 minutes or more
```

## HA configuration for the LAPI pods

You can set up multiple LAPI instances so the failure of a node does not impact
the availability of crowdsec.

To do that, we define a replica count=2 and both instances will use the same
database and CAPI credentials.

The constraints of this setup are

- no local database, but mysql or postgres (in or outside of the cluster)
- no persistent volume for LAPI configuration or data

### Database setup

If you have an existing postgres/mysql/mariadb, create a user for crowdsec and
take note of the credentials.

In this tutorial we deploy a basic instance with:

```sh
$ helm repo add bitnami https://charts.bitnami.com/bitnami
$ helm install \
    mysql bitnami/mysql \
    --create-namespace \
    -n mysql \
    --set auth.RootPassword=verysecretpassword \
    --set auth.database=crowdsec \
    --set auth.username=crowdsec \
    --set auth.password=secretpassword
```

The hostname of the DB will therefore be mysql.mysql.svc.cluster.local

Now, copy your enrollment key at [https://app.crowdsec.net/security-engines](https://app.crowdsec.net/security-engines),
by clicking 'Enroll command' and the "Kubernetes" tab. It is the same every time for your account so you can reuse it
for multiple installations.

### CrowdSec setup

Create a `crowdsec-values.yaml` file, make sure to replace the db credentials and the enrollment key:

```yaml
container_runtime: containerd

agent:
  # we are not setting up traefik but the acquisition section is required.
  acquisition:
    - namespace: traefik
      podName: traefik-*
      program: traefik
lapi:
  replicas: 2
  extraSecrets:
    dbPassword: "secretpassword"
  storeCAPICredentialsInSecret: true
  persistentVolume:
    config:
      enabled: false
    data:
      enabled: false
  env:
    - name: ENROLL_KEY
      value: "abcdefghijklmnopqrstuvwxy"
    - name: ENROLL_INSTANCE_NAME
      value: "my-k8s-cluster"
    - name: ENROLL_TAGS
      value: "k8s linux test"
    - name: DB_PASSWORD
      valueFrom:
        secretKeyRef:
          name: crowdsec-lapi-secrets
          key: dbPassword
config:
  config.yaml.local: |
    db_config:
      type:     mysql
      user:     crowdsec
      password: ${DB_PASSWORD}
      db_name:  crowdsec
      host:     mysql.mysql.svc.cluster.local
      port:     3306
    api:
      server:
        auto_registration: # Activate if not using TLS for authentication
          enabled: true
          token: "${REGISTRATION_TOKEN}"  # /!\ do not change
          allowed_ranges: # /!\ adapt to the pod IP ranges used by your cluster
            - "127.0.0.1/32"
            - "192.168.0.0/16"
            - "10.0.0.0/8"
            - "172.16.0.0/12"

```

and install the crowdsec chart.

```sh
helm install \
    crowdsec crowdsec/crowdsec \
    --create-namespace \
    -n crowdsec \
    -f crowdsec-values.yaml
```

Now you can return to the [console](https://app.crowdsec.net/) to accept the enrollment.

### HA Test

As you can see, the CAPI credentials are persisted in a k8s secret

```
$ kubectl -n crowdsec get secrets crowdsec-capi-credentials -o yaml | yq '.data."online_api_credentials.yaml"' | base64 -d
url: https://api.crowdsec.net/
login: ...
password: ...
papi_url: https://papi.api.crowdsec.net/
```



You can test crowdsec availability by removing any of the LAPI pods, possibly taint the remaining nodes so it won't spawn on them,
and all the log processors will keep connecting randomly to any of the available LAPIs at any time.


## Setup for AppSec (WAF)

Below a basic configuration for AppSec (WAF)

```
# your-values.yaml (option 1)
appsec:
  enabled: true
  acquisitions:
    - source: appsec
      listen_addr: "0.0.0.0:7422"
      path: /
      appsec_config: crowdsecurity/virtual-patching
      labels:
        type: appsec
  env:
    - name: COLLECTIONS
      value: "crowdsecurity/appsec-virtual-patching"
```

Or you can also use your own custom configurations and rules for AppSec:
 
```yaml
# your-values.yaml (option 2)
appsec:
  enabled: true
  acquisitions:
    - source: appsec
      listen_addr: "0.0.0.0:7422"
      path: /
      appsec_config: crowdsecurity/crs-vpatch
      labels:
        type: appsec
  configs:
    mycustom-appsec-config.yaml: |
      name: crowdsecurity/crs-vpatch
      default_remediation: ban
      #log_level: debug
      outofband_rules:
        - crowdsecurity/crs
      inband_rules:
        - crowdsecurity/base-config
        - crowdsecurity/vpatch-*
  env:
    - name: COLLECTIONS
      value: "crowdsecurity/appsec-virtual-patching crowdsecurity/appsec-crs"
```

### With Traefik

In the Traefik `values.yaml`, you need to add the following configuration:

```
# traefik-values.yaml
experimental:
  plugins:
    crowdsec-bouncer:
      moduleName: github.com/maxlerebourg/crowdsec-bouncer-traefik-plugin
      version: v1.3.3
additionalArguments:
  - "--entrypoints.web.http.middlewares=<NAMESPACE>-crowdsec-bouncer@kubernetescrd"
  - "--entrypoints.websecure.http.middlewares=<NAMESPACE>-crowdsec-bouncer@kubernetescrd"
  - "--providers.kubernetescrd"
```

And then, you can apply this middleware to your traefik ingress:

```
# crowdsec-bouncer-middleware.yaml
apiVersion: traefik.io/v1alpha1
kind: Middleware
metadata:
  name: crowdsec-bouncer
  namespace: default
spec:
  plugin:
    crowdsec-bouncer:
      enabled: true
      crowdsecMode: appsec
      crowdsecAppsecEnabled: true
      crowdsecAppsecHost: crowdsec-appsec-service:7422
      crowdsecLapiScheme: http
      crowdsecLapiHost: crowdsec-service:8080
      crowdsecLapiKey: "<YOUR_BOUNCER_KEY>"
```

### With Nginx

Following [this documentation](https://docs.crowdsec.net/u/bouncers/ingress-nginx).

In the nginx ingress `upgrade-values.yaml`, you need to add the following configuration:

```
controller:
  extraInitContainers:
    - name: init-clone-crowdsec-bouncer
      env:
        - name: APPSEC_URL
          value: "http://crowdsec-appsec-service.default.svc.cluster.local:7422"
        - name: APPSEC_FAILURE_ACTION
          value: "passthrough"
        - name: APPSEC_CONNECT_TIMEOUT
          value: "100"
        - name: APPSEC_SEND_TIMEOUT
          value: "100"
        - name: APPSEC_PROCESS_TIMEOUT
          value: "1000"
        - name: ALWAYS_SEND_TO_APPSEC
          value: "false"
        - name: SSL_VERIFY
          value: "true"
```

{{ template "chart.homepageLine" . }}

{{ template "chart.maintainersSection" . }}

{{ template "chart.sourcesSection" . }}

{{ template "chart.requirementsSection" . }}

{{ template "chart.valuesSection" . }}
